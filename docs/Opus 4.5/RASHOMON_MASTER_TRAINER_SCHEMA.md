# Architecture: The "Studio Head" (Rashomon Master Trainer)

**Document Version:** 1.0
**Date:** December 2025
**Context:** Phase 4 (Semi-Autonomous Brand Factory)
**Objective:** Evolving from a "Tool" (User Selects) to a "Factory" (System Learns).

---

## 1. Core Philosophy: The "Studio Head" Paradigm

We introduce a Meta-Agent layer above the Director Personas.
This agent does not generate content; it **manages talent**.

*   **The Talent (Directors):** Specialized agents (Newtonian, Visionary) who interpret inputs.
*   **The Audience (User):** The final arbiter of "Good."
*   **The Studio Head (Master Trainer):** The system that observes User choices to "Prime" the Talent.

**The Goal:** The system should predict the User's "Hidden Spec" before they even click.

---

## 2. The Rashomon Engine (Parallel Perception)

To train the system, we need variance. We use the **Rashomon Effect**: simultaneous, conflicting interpretations of the same reality.

### 2.1 The Process Flow
1.  **Input:** User uploads Image X.
2.  **Rashomon Burst:** System triggers ALL 4 Directors in parallel (headless or cached).
3.  **Divergence Check:**
    *   *Newtonian:* "It's a Physics shot." (Score: P=9, V=3)
    *   *Visionary:* "It's a Vibe shot." (Score: P=4, V=9)
4.  **Presentation:** User sees the "Casting Call" (The Cards).
5.  **The Signal:** User selects **Visionary**.

### 2.2 The Training Data (The "Gap")
The Master Trainer records the **Delta**:
*   *Objective Reality:* Image contained High Physics data.
*   *Subjective Choice:* User chose Low Physics / High Vibe.
*   *Learning:* "User prefers Aesthetic over Realism, even when Realism is objectively better."

---

## 3. The Data Schema: "User Preference Vector"

We do not store simple settings. We store a **Taste Profile** that evolves.

```typescript
interface UserCreativeProfile {
  userId: string;
  
  // The "Taste" Weights (0.0 to 1.0)
  // Updated via Weighted Moving Average (Recent choices matter more)
  biasVector: {
    physicsAffinity: number; // Does user like realistic motion?
    vibeAffinity: number;    // Does user like abstract beauty?
    riskTolerance: number;   // Does user accept hallucinations?
    brevityPreference: number; // Short vs Long commentary?
  };

  // The Vocabulary Cloud
  // Words that appeared in "Winning" pitches vs "Losing" pitches
  vocabularyWeights: {
    [word: string]: number; // e.g., "cinematic": +5, "friction": -2
  };

  // The Roster Performance
  directorWinRate: {
    [directorId: string]: {
      wins: number;
      losses: number;
      streak: number;
    };
  };
}
```

---

## 4. The "Priming" Protocol (Feed-Forward Adjustment)

How the Studio Head influences the Directors *before* they speak.

### 4.1 The Injection
When `vision.ts` calls a Director, it now includes a **"Studio Note"** generated by the Master Trainer.

```typescript
const studioNote = generateStudioNote(userProfile, imageContext);
// Output: "Director, this client hates technical jargon. Focus on the emotional impact. They usually prefer Luma-style lighting."
```

### 4.2 The Adaptation Logic
The Vision Service Prompt is updated:

> **SYSTEM PROMPT:**
> You are [Director Persona].
>
> **THE STUDIO HEAD'S NOTE:**
> "${studioNote}"
>
> **INSTRUCTION:**
> Interpret the image through your Persona, BUT adjust your pitch to align with the Studio Note.
> If the Note says "Focus on Emotion," suppress your technical bias slightly.

---

## 5. The Evolutionary Loop (Automated QC)

The Master Trainer performs nightly/weekly audits of the Roster.

### 5.1 The "Box Office" Report
*   If **"The Provocateur"** has a 0% Selection Rate over 100 jobs:
    *   *Action:* The Master Trainer flags this Persona for **Retooling**.
    *   *Adjustment:* Increases "Risk" or changes "Vocabulary" to make it more distinct.

### 5.2 The "Echo Chamber" Breaker
*   If **User Preference** becomes too narrow (e.g., *Always* selects Newtonian):
    *   *Action:* The Master Trainer forces a **"Wildcard"**.
    *   *Result:* It tells "The Visionary" to try a radically different pitch to see if the user can be "woken up" to new styles.

---

## 6. Implementation Roadmap

### Phase A: Data Collection (The "Silent Observer")
*   **Build:** `eval-rashomon.ts` (The Script).
*   **Action:** Log every Image Upload + Director Scores + User Selection to a new table: `learning_events`.
*   **No Training yet.** Just gather the "Ground Truth."

### Phase B: The Preference Engine (The "Memory")
*   **Build:** `UserCreativeProfile` in Postgres.
*   **Action:** A background worker processes `learning_events` to update the User's `biasVector`.

### Phase C: The Feedback Loop (The "Whisper")
*   **Build:** Inject `studioNote` into the Gemini prompt in `vision.ts`.
*   **Result:** The Directors start "remembering" what the user likes.

---

**End of Document**
